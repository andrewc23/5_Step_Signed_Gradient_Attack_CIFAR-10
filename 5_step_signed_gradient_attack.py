# -*- coding: utf-8 -*-
"""5_Step_Signed_Gradient_Attack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LAK5Nz1PqqkqI7ukEsU6A4GYENmKqQI8

##Andrew Clark
##Investigation of a 5-Step Signed Gradient Attack on CIFAR-10 Dataset

Part A: Training a CNN on Unperturbed Images
---
"""

LOG_DIR = './logs'
get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(LOG_DIR)
)

!if [ -f ngrok ] ; then echo "Ngrok already installed" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi

get_ipython().system_raw('./ngrok http 6006 &')

! curl -s http://localhost:4040/api/tunnels | python3 -c \
    "import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))"

# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514
import tensorflow as tf
import numpy as np
import scipy.misc 
try:
    from StringIO import StringIO  # Python 2.7
except ImportError:
    from io import BytesIO         # Python 3.x


class Logger(object):
    
    def __init__(self, log_dir):
        """Create a summary writer logging to log_dir."""
        self.writer = tf.summary.FileWriter(log_dir)

    def scalar_summary(self, tag, value, step):
        """Log a scalar variable."""
        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])
        self.writer.add_summary(summary, step)

    def image_summary(self, tag, images, step):
        """Log a list of images."""

        img_summaries = []
        for i, img in enumerate(images):
            # Write the image to a string
            try:
                s = StringIO()
            except:
                s = BytesIO()
            scipy.misc.toimage(img).save(s, format="png")

            # Create an Image object
            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),
                                       height=img.shape[0],
                                       width=img.shape[1])
            # Create a Summary value
            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))

        # Create and write Summary
        summary = tf.Summary(value=img_summaries)
        self.writer.add_summary(summary, step)
        
    def histo_summary(self, tag, values, step, bins=1000):
        """Log a histogram of the tensor of values."""

        # Create a histogram using numpy
        counts, bin_edges = np.histogram(values, bins=bins)

        # Fill the fields of the histogram proto
        hist = tf.HistogramProto()
        hist.min = float(np.min(values))
        hist.max = float(np.max(values))
        hist.num = int(np.prod(values.shape))
        hist.sum = float(np.sum(values))
        hist.sum_squares = float(np.sum(values**2))

        # Drop the start of the first bin
        bin_edges = bin_edges[1:]

        # Add bin edges and counts
        for edge in bin_edges:
            hist.bucket_limit.append(edge)
        for c in counts:
            hist.bucket.append(c)

        # Create and write Summary
        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])
        self.writer.add_summary(summary, step)
        self.writer.flush()

# torch and torchvision imports
import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
import torch.optim as optim

from torch.optim.lr_scheduler import StepLR

#logger = Logger('./logs')
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') 
device #check if the gpu is being used

from tqdm import tqdm_notebook
# Reading in the dataset
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,
                                          shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=16,
                                         shuffle=False)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


# Defining the model
class View(nn.Module):
    def __init__(self,o):
        super().__init__()
        self.o = o

    def forward(self,x):
        return x.view(-1, self.o)
    
class allcnn_t(nn.Module):
    def __init__(self, c1=96, c2= 192):
        super().__init__()
        d = 0.5

        def convbn(ci,co,ksz,s=1,pz=0):
            return nn.Sequential(
                nn.Conv2d(ci,co,ksz,stride=s,padding=pz),
                nn.ReLU(True),
                nn.BatchNorm2d(co))

        self.m = nn.Sequential(
            #nn.Dropout(0.2), #Change the network by eliminating the first dropout layer 
            convbn(3,c1,3,1,1),
            convbn(c1,c1,3,1,1),
            convbn(c1,c1,3,2,1),
            nn.Dropout(d),
            convbn(c1,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,2,1),
            nn.Dropout(d),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,10,1,1),
            nn.AvgPool2d(8),
            View(10))

        print('Num parameters: ', sum([p.numel() for p in self.m.parameters()]))

    def forward(self, x):
        return self.m(x)

# The training loop

def train(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot):
    #create lists for plotting 
    training_loss_list=[]
    training_accuracy_list=[]
    val_accuracy_list=[]
    val_loss_list=[]
    model = net.to(device)
    total_step = len(train_loader)
    overall_step = 0
    for epoch in tqdm_notebook(range(epochs)):
        correct = 0
        total = 0
        model.train()
        for i, (images, labels) in enumerate(train_loader):
            # Move tensors to configured device
            images = images.to(device)
            labels = labels.to(device)
            #Forward Pass
            outputs = model(images)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            #training_loss_list.append(loss.item())
            if (i+1) % 1000 == 0:
              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))
            if plot:
              info = { ('loss_' + model_name): loss.item() }
        training_loss_list.append(loss.item())

              #for tag, value in info.items():
                #logger.scalar_summary(tag, value, overall_step+1)

        ####evaluate the test set to get the test accuracy
        model.eval()
        with torch.no_grad():
          correct = 0
          total = 0
          error=0
          for i, (images, labels) in enumerate(test_loader):
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            #val_loss_list.append(loss.item())#append the validation loss to val_loss_list
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
          error=(1-(correct/total))*100
          val_accuracy_list.append(error)# append to the validation accuracy list the number correct
          val_loss_list.append(loss.item())#append the validation loss to val_loss_list

        ###evaluate the train set to get the train accuracy 
        with torch.no_grad():
          correct = 0
          total = 0
          error=0
          for i, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
          error=(1-(correct/total))
          training_accuracy_list.append(error)# append to the validation accuracy list the number correct 



##FINAL TEST SET EVALUATION##
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        for i, (images, labels) in enumerate(test_loader):
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))
    return training_loss_list,val_loss_list,training_accuracy_list,val_accuracy_list

model = allcnn_t().to(device)
#TODO: Set it as number of epochs states in the question
epochs = 100
# TODO: Define the loss function as asked in the question
criterion = nn.CrossEntropyLoss()

# # TODO: Set parameters as stated in the question
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
# Training loop called here
#train(model, optimizer, criterion, trainloader, testloader, epochs, 'cnn', True)

train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list = train(model, optimizer, criterion, trainloader, testloader, epochs, 'cnn', True)

#save model and model parameters
from google.colab import files 

#save the model
torch.save(model,'model_final_2')
#save the state dict
torch.save(model.state_dict(),'state_dict_final_2')


#save the training loss list
torch.save(train_loss_list,'training_loss_list_2')
#save the validation loss list
torch.save(val_loss_list,'validation_loss_list_2')
#save the training accuracy list
torch.save(train_accuracy_list,'train_accuracy_list_2')
#save the validation accuracy list 
torch.save(val_accuracy_list,'validation_accuracy_list_2')


#download the model
files.download('model_final_2')
#download state dict
files.download('state_dict_final_2')
#download training loss
files.download('training_loss_list_2')
#download validation loss
files.download('validation_loss_list_2')
#download training accuracy
files.download('train_accuracy_list_2')
#download the validation accuracy
files.download('validation_accuracy_list_2')

#upload what is required
uploaded_training_error_list=torch.load('train_accuracy_list_1')
uploaded_training_loss=torch.load('training_loss_list_1')
uploaded_val_error=torch.load('validation_accuracy_list_1')
uploaded_val_loss=torch.load('validation_loss_list_1')

#Create plots 
import matplotlib.pyplot as plt

train_error_list_done=[x*100 for x in train_accuracy_list]

plt.plot(train_error_list_done)
plt.title('Training Error')
plt.xlabel('Epoch')
plt.ylabel('Training Error (%)')
plt.show()

plt.plot(train_loss_list)
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Training Loss')
plt.show()

plt.plot(val_accuracy_list)
plt.title('Validation Error')
plt.xlabel('Epoch')
plt.ylabel('Validation Error (%)')
plt.show()


plt.plot(val_loss_list)
plt.title('Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Validation Loss')
plt.show()

"""Part B: Perturbing Images Using a 5-Step Signed Gradient Attack
---
"""

from google.colab import files 
files.upload()

model_params_final=torch.load('state_dict_final_2')

# Defining the model
class View(nn.Module):
    def __init__(self,o):
        super().__init__()
        self.o = o

    def forward(self,x):
        return x.view(-1, self.o)
    
class allcnn_t(nn.Module):
    def __init__(self, c1=96, c2= 192):
        super().__init__()
        d = 0.5

        def convbn(ci,co,ksz,s=1,pz=0):
            return nn.Sequential(
                nn.Conv2d(ci,co,ksz,stride=s,padding=pz),
                nn.ReLU(True),
                nn.BatchNorm2d(co))

        self.m = nn.Sequential(
            #nn.Dropout(0.2), #eliminte first dropout layer 
            convbn(3,c1,3,1,1),
            convbn(c1,c1,3,1,1),
            convbn(c1,c1,3,2,1),
            nn.Dropout(d),
            convbn(c1,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,2,1),
            nn.Dropout(d),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,10,1,1),
            nn.AvgPool2d(8),
            View(10))

        print('Num parameters: ', sum([p.numel() for p in self.m.parameters()]))

    def forward(self, x):
        return self.m(x)

model = allcnn_t().to(device)

#load in the model using the saved parameters

model_loaded=model
model_loaded.load_state_dict(torch.load('state_dict_final_2'))
model_loaded.eval()

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=100,
                                         shuffle=False) 
 
images_list=[]
labels_list=[]
for i, (images, labels) in enumerate(testloader):
  # Move tensors to configured device
  images = images.to(device)
  labels = labels.to(device)
  images_list.append(images)
  labels_list.append(labels)
  if i ==0:
    break

xs,ys=images_list,labels_list
criterion = nn.CrossEntropyLoss()

#compute the dx
xs = images.to(device)
ys = labels.to(device)
xs.requires_grad=True
outputs = model(xs)
loss = criterion(outputs, labels)
dx=xs.grad.data.clone()

total=0
correct=0
_, predicted = torch.max(outputs.data, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()

#figure out which images have been classified correctly
idx_mat=(predicted==labels)

#grab the indices where the images have been classified correctly and not correctly 
idx_false=[]
idx_true=[]
for i,x in enumerate(idx_mat):
  if x==False:
    idx_false.append(i)
  elif x==True:
    idx_true.append(i)

#display some of the dxs

#plot for correct image 
correct_image_1=dx[idx_true[0]]
correct_image_1=correct_image_1.cpu()

correct_image_1=correct_image_1.permute(1,2,0)

correct_image_1=correct_image_1/(2*(correct_image_1.max()))
plt.figure()
plt.imshow(correct_image_1)
plt.title('dx For A Correctly Classified Image')

#plot for correct image 
correct_image_1=dx[idx_true[1]]
correct_image_1=correct_image_1.cpu()

correct_image_1=correct_image_1.permute(1,2,0)

correct_image_1=correct_image_1/(2*(correct_image_1.max()))
plt.figure()
plt.imshow(correct_image_1)
plt.title('dx For A Correctly Classified Image')

##now plot for false images
false_image_1=dx[idx_false[0]]
false_image_1=false_image_1.cpu()

false_image_1=false_image_1.permute(1,2,0)

false_image_1=false_image_1/(2*(false_image_1.max()))

plt.figure()
plt.imshow(false_image_1)
plt.title('dx For An Incorrectly Classified Image')

false_image_1=dx[idx_false[1]]
false_image_1=false_image_1.cpu()

false_image_1=false_image_1.permute(1,2,0)

false_image_1=false_image_1/(2*(false_image_1.max()))

plt.figure()
plt.imshow(false_image_1)
plt.title('dx For An Incorrectly Classified Image')

#xs, ys = mini-batch of inputs and targets

xs,ys=images_list,labels_list
criterion = nn.CrossEntropyLoss()
ell_loss_list=[]
dx_list=[]
eps=(8/(255*2)) #scale epsilon appropriately 
for x,y in zip(xs, ys):
  for k in range(5):
    copy_of_x=x.clone().detach()
    #create a copy of x 
    x.requires_grad=True
    # forward propagate x through the network
    yh=model_loaded(x)
    loss = criterion(yh, y)
    #loss=loss.forward(yh,y)
    # backprop the loss
    loss.backward()
    dx = x.grad.data.clone()
    dx_list.append(dx) #save the x bar gradient to a list for plotting 
    x = copy_of_x+eps*torch.sign(dx)
    # record loss on the perturbed image
    ell = loss.item()
    ell_loss_list.append(ell)

import matplotlib.pyplot as plt

plt.title('Loss on Perturbed Images as a Function of the \n Number of Steps in the Attack (Averaged Across Mini-batch)')
plt.xlabel('Step')
plt.ylabel('Loss')
plt.plot(ell_loss_list)

#plot a 5 Perturbed image just to see what it looks like 
correct_image_1=x[0]
correct_image_1=correct_image_1.cpu()

correct_image_1=correct_image_1.permute(1,2,0)

correct_image_1=correct_image_1/(correct_image_1.max())
plt.figure()
plt.imshow(correct_image_1)
plt.title('Image Perturbed by a 5-Step Attack')

"""Part C: Investing CNN Architecture Performance on Perturbed vs. Unperturbed Images
---
"""

##Compute accuracy on unperturbed images##

model.eval()
with torch.no_grad():
  correct = 0
  total = 0
  for i, (images, labels) in enumerate(testloader):
    images = images.to(device)
    labels = labels.to(device)
    outputs = model_loaded(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
    
  print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))

##Compute accuracy on images##
eps=(8/(255*2)) #scale epsilon appropriately 
correct = 0
total = 0
for i, (images, labels) in enumerate(testloader):
    images = images.to(device)
    labels = labels.to(device)
    outputs = model_loaded(images)
    
    copy_of_images=images.clone().detach()
    #create a copy of x 
    images.requires_grad=True
    # forward propagate x through the network
    yh=model_loaded(images)
    loss = criterion(yh, y)
    #loss=loss.forward(yh,y)
    # backprop the loss
    loss.backward()
    dx = images.grad.data.clone()
    images = copy_of_images+eps*torch.sign(dx)
    model.eval()
    with torch.no_grad():
      _, predicted = torch.max(outputs.data, 1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
    
print('Accuracy of the network on the perturbed test images: {} %'.format(100 *(1- (correct / total))))